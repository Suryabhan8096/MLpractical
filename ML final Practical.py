#!/usr/bin/env python
# coding: utf-8

# In[19]:


# 2)

from numpy import random
import matplotlib.pyplot as plt
import seaborn as sns
sns.distplot(random.normal(size=1000),hist=False)
plt.show()


# In[20]:


#3
import numpy as np
import matplotlib.pyplot as plt
x=np.array([1,2,3,4])
y=np.array([2,3,5,7])
plt.scatter(x,y,color='blue',label='Data point')
m,b=np.polyfit(x,y,1)
plt.plot(x,m*x+b,color='red',label='Regression line')
plt.legend()
plt.show()


# In[21]:


#4
import matplotlib.pyplot as plt
from scipy import stats
x=[5,7,8,73,2,456,77,5,67,7,9]
y=[99,86,87,88,111,86,103,87,94,78,77]
slope,intercept,r,p,std_err=stats.linregress(x,y)
def myfunc(x):
    return slope*x+intercept
mymodel=list(map(myfunc,x))
plt.scatter(x,y)
plt.plot(x,mymodel)
plt.show()


# In[26]:


# 5. Write a python program to predict the speed of a 5 years old car.

import numpy as np

from scipy import stats

import matplotlib.pyplot as plt

#Sample data: ages of cars (in years) and their speeds (in km/h) 
ages= np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

speeds=np.array([120, 115, 110, 105, 100, 95, 90, 85, 80, 75])
slope, intercept, r_value, p_value, std_err =stats.linregress(ages, speeds)

#Function to predict speed based on age

def predict_speed(age):
    
    return slope*age + intercept

predicted_speed =predict_speed(5)

print(f"The predicted speed of a 5-year-old car is {predicted_speed: 2f} km/h")

plt.scatter(ages, speeds, color='blue', label='Actual data')

plt.plot(ages, predict_speed(ages), c√≥lor='red', label='Regression line')

plt.xlabel('Age of car (years)')

plt.ylabel('Speed of car (km/h)')

plt.legend()

plt.show()


# In[29]:


# 6. Write a python program to print the coefficient values of the regres

import numpy as np

from sklearn.linear_model import LinearRegression

# Sample data

X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])

y = np.dot(X, np.array([1, 2])) + 3

# Create and fit the model

model = LinearRegression().fit(X, y)

# Print the coefficients

print("Coefficients:", model.coef_)

print("Intercept:", model.intercept_)


# In[39]:


# 8. Write a python program to display the plot we can use the functions plot) and th

import matplotlib.pyplot as plt

#Data for plotting

x=[1,2,3,4]

y=[2, 4,1,3]

#Creating the plot

plt.plot(x, y)

#Adding labels and title

plt.xlabel('x-axis')

plt.ylabel('y-axis')

plt.title('Simple Plot')

#Displaying the plot

plt.show()
 


# In[47]:


# 9. Write a python program to data generated by the function make_blobs() are blobs that can be utilized for clustering.

import matplotlib.pyplot as plt

from sklearn.datasets import make_blobs

from sklearn.cluster import KMeans

#Generate synthetic data

#Apply K-Means clustering

X,y=make_blobs(n_samples=300,centers=4, n_features=2, cluster_std=1.0, random_state=42)

# kmeans.fit(X)

kmeans =KMeans(n_clusters=4, random_state=42)

kmeans.fit(X)

y_kmeans = kmeans.predict(X)

#Plot the clusters

plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')

centers = kmeans.cluster_centers

plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X')

plt.xlabel('Feature 1')

plt.ylabel('Feature 2')

plt.title('K-Means Clustering')

plt.show()


# In[52]:


# 10. Write a python program to random multi-label classification data is created by the function make make_multilabel_classification()

from sklearn.datasets import make_multilabel_classification

import matplotlib.pyplot as plt

#Generate random multi-label classification data

X, y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=5, n_labels=3, random_state  = 42 )

#Print the shape of the features and labels

print("Features shape:", X.shape)

print("Labels shape:", y.shape)

#Plot the first two features

plt.scatter ( X [:,0], X [:,1], marker='o', c =y[:,0] ,edgecolor ='k')

plt.title("Random Multi-label Classification Data")

plt.xlabel("Feature 1")

plt.ylabel("Feature 2")

plt.show()



# In[59]:


# 11Write a python program to implement the KNN algorithm.

import numpy as np

from sklearn.datasets import load_iris

from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import accuracy_score

#Load the Iris dataset

iris = load_iris()

X, y= iris.data, iris.target

#Split the dataset into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#Create the KNN classifier

knn=KNeighborsClassifier(n_neighbors=3)

# Fit the classifier to the training data

knn.fit(X_train, y_train)

#Predict the labels for the test set

y_pred =knn.predict(X_test)

#Calculate the accuracy of the classifier

accuracy = accuracy_score(y_test, y_pred)

print(f'Accuracy: {accuracy * 100:2f}%')


# In[66]:


#12. Write a python program to creating a dataframe to implement one hot encoding from CSV file.

import pandas as pd

# Load the CSV file into a DataFrame

df=pd.read_csv("loan.csv")

# Identify categorical columns

categorical_columns= df.select_dtypes(include=['object']).columns

# Perform one-hot encoding

df_encoded=pd.get_dummies(df, columns=categorical_columns)

#Print the encoded

print(df_encoded)


# In[ ]:




